{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ExperimentPrice.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alessiomongoli/Sentiment_Lexicon/blob/main/ExperimentPrice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/alessiomongoli/Sentiment_Lexicon.git"
      ],
      "metadata": {
        "id": "EILrBQsyWKIR",
        "outputId": "13b9bf2d-9e22-4f99-ba40-599924fe1a48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Sentiment_Lexicon'...\n",
            "remote: Enumerating objects: 161, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 161 (delta 4), reused 0 (delta 0), pack-reused 145\u001b[K\n",
            "Receiving objects: 100% (161/161), 243.31 KiB | 11.59 MiB/s, done.\n",
            "Resolving deltas: 100% (81/81), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1mpL3_URUIDlY0I5MiaCi_tWXqGdA2-6k"
      ],
      "metadata": {
        "id": "UtEWCB0ehNjh",
        "outputId": "2181edb4-0de1-43ae-b6fb-2fc0a021aeeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1mpL3_URUIDlY0I5MiaCi_tWXqGdA2-6k\n",
            "To: /content/glove.840B.300d.pkl\n",
            "100% 2.80G/2.80G [00:27<00:00, 100MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install import-ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaBueLcGhL7m",
        "outputId": "c29b20ba-af85-4f75-817d-371be5df8410"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting import-ipynb\n",
            "  Downloading import_ipynb-0.1.4-py3-none-any.whl (4.1 kB)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from import-ipynb) (5.4.0)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from import-ipynb) (5.5.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (57.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (4.4.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (5.1.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (0.7.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->import-ipynb) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->import-ipynb) (0.2.5)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->import-ipynb) (2.15.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat->import-ipynb) (4.11.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->import-ipynb) (4.3.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.18.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (21.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (4.1.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (5.8.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (4.12.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->import-ipynb) (3.8.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->IPython->import-ipynb) (0.7.0)\n",
            "Installing collected packages: import-ipynb\n",
            "Successfully installed import-ipynb-0.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import import_ipynb\n",
        "import sys\n",
        "sys.path.append('/content/Sentiment_Lexicon/')"
      ],
      "metadata": {
        "id": "B3OO9CAxeKt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/Sentiment_Lexicon/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nx9w1fDOhRSY",
        "outputId": "89b645fe-748f-4a0a-ee4a-aa65138cc043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Github/Colab Notebooks/project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Musical_Instruments.json.gz\n",
        "!wget http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/meta_Musical_Instruments.json.gz"
      ],
      "metadata": {
        "id": "ZF4IVpWhTzEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "import nltk \n",
        "import string\n",
        "\n",
        "from Data_induction.PreProcessing import preprocessing_experiment_price\n",
        "from Data_induction.TrainSVM import LinearCoefficentsSVM\n",
        "from glove.Glove import load__all_glove_word, glove_test\n",
        "from Data_induction.Seed_Data import SeedDataset\n",
        "from Neural_model.EarlyStopping import EarlyStopping\n",
        "from Neural_model.Neural import RegressionModel\n",
        "from Neural_model.Train_predict_NN import train, predict\n",
        "from Utils.DataframeCreation import creation_dataframe, create_dataframe_price_equal_size ,getDF, parse, compute_statistics_dataframe"
      ],
      "metadata": {
        "id": "QB_q9Ng9qZr3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf26f4a7-90b5-4bcb-c9c3-e81f275db448"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "importing Jupyter notebook from /content/drive/My Drive/Github/Colab Notebooks/project/Data_induction/PreProcessing.ipynb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "importing Jupyter notebook from /content/drive/My Drive/Github/Colab Notebooks/project/Data_induction/TrainSVM.ipynb\n",
            "importing Jupyter notebook from /content/drive/My Drive/Github/Colab Notebooks/project/glove/Glove.ipynb\n",
            "importing Jupyter notebook from /content/drive/My Drive/Github/Colab Notebooks/project/Data_induction/Seed_Data.ipynb\n",
            "importing Jupyter notebook from /content/drive/My Drive/Github/Colab Notebooks/project/Neural_model/EarlyStopping.ipynb\n",
            "importing Jupyter notebook from /content/drive/My Drive/Github/Colab Notebooks/project/Neural_model/Neural.ipynb\n",
            "importing Jupyter notebook from /content/drive/My Drive/Github/Colab Notebooks/project/Neural_model/Train_predict_NN.ipynb\n",
            "importing Jupyter notebook from /content/drive/My Drive/Github/Colab Notebooks/project/Utils/DataframeCreation.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def experiment_price_dataframe(df, negation_type, category):\n",
        "  X, y, frequencies, vocabulary = preprocessing_experiment_price(df, negation_type)\n",
        "  coefficents = LinearCoefficentsSVM(X, y, category, negation_type)\n",
        "  data = creation_dataframe(vocabulary,coefficents, frequencies)\n",
        "  return data\n",
        "  \n",
        "def searching(vocab):\n",
        "  top_k = search(vocab, True)\n",
        "  lowest_k = search(vocab, False)\n",
        "  pos, neg = count(vocab) \n",
        "  return top_k, lowest_k, pos, neg\n",
        "\n",
        "def search(res, reverse):\n",
        "  rlist = sorted(res, key=res.get, reverse=reverse)[:] #[:10] if want to select the top 10\n",
        "  dictionary = {}\n",
        "  for key in rlist:\n",
        "    dictionary[key] = res[key]\n",
        "  return dictionary"
      ],
      "metadata": {
        "id": "6i2MUcizSFe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pipeline_experiment(Data, glove, CATEGORY, negation_type):\n",
        "  Data = Data[Data['Frequence']>=500]\n",
        "  Data.reset_index(drop=True, inplace=True)\n",
        "  Data=Data[Data['Token'].isin(glove.keys())]\n",
        "  Data.reset_index(drop=True, inplace=True)\n",
        "  Data['Embedding']=Data['Token'].apply(lambda x: glove[x])\n",
        "  Data.reset_index(drop=True, inplace=True)\n",
        "  embedding=dict(zip(Data.Token, Data.Embedding))\n",
        "  Dataset=SeedDataset(list(Data['Token']),embedding, pol=list(Data['Polarity']))\n",
        "  trained_model = train(Dataset,CATEGORY, negation_type)\n",
        "  all_vocabulary= Dataset.get_result()\n",
        "  glove_wo_pol=glove_test(glove, list(Data['Token']))\n",
        "  non_seed_data={w:0 for w in glove_wo_pol.keys()}\n",
        "  non_seed_dataset = SeedDataset(list(non_seed_data.keys()),glove_wo_pol,split='test')\n",
        "  results = predict(trained_model, non_seed_dataset,CATEGORY, negation_type)\n",
        "  all_vocabulary.update(results)\n",
        "  \n",
        "  return all_vocabulary\n"
      ],
      "metadata": {
        "id": "gHF9leDZfMjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count(res):\n",
        "  pos= 0\n",
        "  neg = 0\n",
        "  res_filtered = {k: v for k, v in res.items() if v<=-0.1 or v>=0.1}\n",
        "  for k, v in res_filtered.items():\n",
        "    if v >= 0:\n",
        "        pos += 1\n",
        "    else:\n",
        "        neg += 1\n",
        "  return pos, neg"
      ],
      "metadata": {
        "id": "nyAy3nG9gTLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CATEGORY=\"reviews_Musical_Instruments\"\n",
        "path_category ='/content/Sentiment_Lexicon/'+CATEGORY+'.json.gz'\n",
        "path_metadata = '/content/Sentiment_Lexicon/'+'meta_'+CATEGORY[8:]+'.json.gz'\n",
        "negation_type = 'normal' \n",
        "REPOSITORY = '/content/Sentiment_Lexicon/'\n",
        "SAVE_DATAFRAME_FILE=True"
      ],
      "metadata": {
        "id": "C-GuIEkyOWh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_low_price, df_medium_price, df_high_price = create_dataframe_price_equal_size(path_category, path_metadata)\n",
        "min_low, max_low, mean_price_low, num_reviews_low, mean_lenght_low = compute_statistics_dataframe(df_low_price)\n",
        "min_medium, max_medium, mean_price_medium, num_reviews_medium, mean_lenght_medium = compute_statistics_dataframe(df_medium_price)\n",
        "min_high, max_high, mean_price_high, num_reviews_high, mean_lenght_high = compute_statistics_dataframe(df_high_price)"
      ],
      "metadata": {
        "id": "hCaQyvaxosVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_low_price = df_low_price.drop(columns=['price'])\n",
        "df_medium_price = df_medium_price.drop(columns=['price'])\n",
        "df_high_price = df_high_price.drop(columns=['price'])"
      ],
      "metadata": {
        "id": "MpWYu20KKoDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove=load__all_glove_word(REPOSITORY+'content/glove.840B.300d.pkl')"
      ],
      "metadata": {
        "id": "bZgw5mZGOJ1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "dataframe_low=experiment_price_dataframe(df_low_price, negation_type ,CATEGORY)\n",
        "dataframe_medium=experiment_price_dataframe(df_medium_price, negation_type ,CATEGORY)\n",
        "dataframe_high=experiment_price_dataframe(df_high_price, negation_type ,CATEGORY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyalejLhO0n7",
        "outputId": "9e21988f-8296-4527-a3ce-ac6016c0f780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2min 52s, sys: 587 ms, total: 2min 52s\n",
            "Wall time: 2min 52s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "result_low=pipeline_experiment(dataframe_low,glove, CATEGORY, negation_type)\n",
        "result_medium=pipeline_experiment(dataframe_medium, glove, CATEGORY, negation_type)\n",
        "result_high=pipeline_experiment(dataframe_high, glove, CATEGORY, negation_type)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXpmphC2P2MT",
        "outputId": "3d56e8b0-a165-4338-ea2f-d842825ec6b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0:\n",
            "\tLoss decreased (inf --> 0.078810).  Saving model ...\n",
            "epoch 1:\n",
            "\tLoss decreased (0.078810 --> 0.049104).  Saving model ...\n",
            "epoch 2:\n",
            "\tLoss decreased (0.049104 --> 0.040814).  Saving model ...\n",
            "epoch 3:\n",
            "\tLoss decreased (0.040814 --> 0.035461).  Saving model ...\n",
            "epoch 4:\n",
            "\tLoss decreased (0.035461 --> 0.031257).  Saving model ...\n",
            "epoch 5:\n",
            "\tLoss decreased (0.031257 --> 0.026301).  Saving model ...\n",
            "epoch 6:\n",
            "\tLoss decreased (0.026301 --> 0.023560).  Saving model ...\n",
            "epoch 7:\n",
            "\tLoss decreased (0.023560 --> 0.022738).  Saving model ...\n",
            "epoch 8:\n",
            "\tLoss decreased (0.022738 --> 0.021539).  Saving model ...\n",
            "epoch 9:\n",
            "\tLoss decreased (0.021539 --> 0.020532).  Saving model ...\n",
            "epoch 10:\n",
            "\tLoss decreased (0.020532 --> 0.018177).  Saving model ...\n",
            "epoch 11: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 12:\n",
            "\tLoss decreased (0.018177 --> 0.017465).  Saving model ...\n",
            "epoch 13:\n",
            "\tLoss decreased (0.017465 --> 0.016755).  Saving model ...\n",
            "epoch 14:\n",
            "\tLoss decreased (0.016755 --> 0.015790).  Saving model ...\n",
            "epoch 15:\n",
            "\tLoss decreased (0.015790 --> 0.013872).  Saving model ...\n",
            "epoch 16: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 17: \n",
            "\tearly stopping counter: 2 out of 20\n",
            "epoch 18: \n",
            "\tearly stopping counter: 3 out of 20\n",
            "epoch 19:\n",
            "\tLoss decreased (0.013872 --> 0.012974).  Saving model ...\n",
            "epoch 20:\n",
            "\tLoss decreased (0.012974 --> 0.011960).  Saving model ...\n",
            "epoch 21: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 22:\n",
            "\tLoss decreased (0.011960 --> 0.011634).  Saving model ...\n",
            "epoch 23:\n",
            "\tLoss decreased (0.011634 --> 0.011543).  Saving model ...\n",
            "epoch 24:\n",
            "\tLoss decreased (0.011543 --> 0.011407).  Saving model ...\n",
            "epoch 25:\n",
            "\tLoss decreased (0.011407 --> 0.011041).  Saving model ...\n",
            "epoch 26:\n",
            "\tLoss decreased (0.011041 --> 0.010501).  Saving model ...\n",
            "epoch 27: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 28:\n",
            "\tLoss decreased (0.010501 --> 0.009830).  Saving model ...\n",
            "epoch 29:\n",
            "\tLoss decreased (0.009830 --> 0.009259).  Saving model ...\n",
            "epoch 30: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 31: \n",
            "\tearly stopping counter: 2 out of 20\n",
            "epoch 32:\n",
            "\tLoss decreased (0.009259 --> 0.009109).  Saving model ...\n",
            "epoch 33: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 34:\n",
            "\tLoss decreased (0.009109 --> 0.008791).  Saving model ...\n",
            "epoch 35:\n",
            "\tLoss decreased (0.008791 --> 0.008540).  Saving model ...\n",
            "epoch 36: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 37: \n",
            "\tearly stopping counter: 2 out of 20\n",
            "epoch 38:\n",
            "\tLoss decreased (0.008540 --> 0.008519).  Saving model ...\n",
            "epoch 39: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 40: \n",
            "\tearly stopping counter: 2 out of 20\n",
            "epoch 41:\n",
            "\tLoss decreased (0.008519 --> 0.007489).  Saving model ...\n",
            "epoch 42:\n",
            "\tLoss decreased (0.007489 --> 0.007391).  Saving model ...\n",
            "epoch 43: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 44: \n",
            "\tearly stopping counter: 2 out of 20\n",
            "epoch 45:\n",
            "\tLoss decreased (0.007391 --> 0.007079).  Saving model ...\n",
            "epoch 46: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 47:\n",
            "\tLoss decreased (0.007079 --> 0.006900).  Saving model ...\n",
            "epoch 48: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 49: \n",
            "\tearly stopping counter: 2 out of 20\n",
            "epoch 50: \n",
            "\tearly stopping counter: 3 out of 20\n",
            "epoch 51:\n",
            "\tLoss decreased (0.006900 --> 0.006330).  Saving model ...\n",
            "epoch 52: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 53: \n",
            "\tearly stopping counter: 2 out of 20\n",
            "epoch 54: \n",
            "\tearly stopping counter: 3 out of 20\n",
            "epoch 55:\n",
            "\tLoss decreased (0.006330 --> 0.006157).  Saving model ...\n",
            "epoch 56: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 57:\n",
            "\tLoss decreased (0.006157 --> 0.005891).  Saving model ...\n",
            "epoch 58: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 59: \n",
            "\tearly stopping counter: 2 out of 20\n",
            "epoch 60: \n",
            "\tearly stopping counter: 3 out of 20\n",
            "epoch 61: \n",
            "\tearly stopping counter: 4 out of 20\n",
            "epoch 62: \n",
            "\tearly stopping counter: 5 out of 20\n",
            "epoch 63: \n",
            "\tearly stopping counter: 6 out of 20\n",
            "epoch 64:\n",
            "\tLoss decreased (0.005891 --> 0.005854).  Saving model ...\n",
            "epoch 65: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 66:\n",
            "\tLoss decreased (0.005854 --> 0.005548).  Saving model ...\n",
            "epoch 67: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 68: \n",
            "\tearly stopping counter: 2 out of 20\n",
            "epoch 69: \n",
            "\tearly stopping counter: 3 out of 20\n",
            "epoch 70: \n",
            "\tearly stopping counter: 4 out of 20\n",
            "epoch 71:\n",
            "\tLoss decreased (0.005548 --> 0.005424).  Saving model ...\n",
            "epoch 72:\n",
            "\tLoss decreased (0.005424 --> 0.004866).  Saving model ...\n",
            "epoch 73: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 74: \n",
            "\tearly stopping counter: 2 out of 20\n",
            "epoch 75: \n",
            "\tearly stopping counter: 3 out of 20\n",
            "epoch 76: \n",
            "\tearly stopping counter: 4 out of 20\n",
            "epoch 77: \n",
            "\tearly stopping counter: 5 out of 20\n",
            "epoch 78: \n",
            "\tearly stopping counter: 6 out of 20\n",
            "epoch 79: \n",
            "\tearly stopping counter: 7 out of 20\n",
            "epoch 80: \n",
            "\tearly stopping counter: 8 out of 20\n",
            "epoch 81: \n",
            "\tearly stopping counter: 9 out of 20\n",
            "epoch 82: \n",
            "\tearly stopping counter: 10 out of 20\n",
            "epoch 83: \n",
            "\tearly stopping counter: 11 out of 20\n",
            "epoch 84: \n",
            "\tearly stopping counter: 12 out of 20\n",
            "epoch 85: \n",
            "\tearly stopping counter: 13 out of 20\n",
            "epoch 86: \n",
            "\tearly stopping counter: 14 out of 20\n",
            "epoch 87: \n",
            "\tearly stopping counter: 15 out of 20\n",
            "epoch 88: \n",
            "\tearly stopping counter: 16 out of 20\n",
            "epoch 89: \n",
            "\tearly stopping counter: 17 out of 20\n",
            "epoch 90: \n",
            "\tearly stopping counter: 18 out of 20\n",
            "epoch 91: \n",
            "\tearly stopping counter: 19 out of 20\n",
            "epoch 92: \n",
            "\tearly stopping counter: 20 out of 20\n",
            "Early stopping\n",
            "epoch 0:\n",
            "\tLoss decreased (inf --> 0.075991).  Saving model ...\n",
            "epoch 1:\n",
            "\tLoss decreased (0.075991 --> 0.046748).  Saving model ...\n",
            "epoch 2:\n",
            "\tLoss decreased (0.046748 --> 0.040838).  Saving model ...\n",
            "epoch 3:\n",
            "\tLoss decreased (0.040838 --> 0.035954).  Saving model ...\n",
            "epoch 4:\n",
            "\tLoss decreased (0.035954 --> 0.033141).  Saving model ...\n",
            "epoch 5:\n",
            "\tLoss decreased (0.033141 --> 0.029067).  Saving model ...\n",
            "epoch 6:\n",
            "\tLoss decreased (0.029067 --> 0.026205).  Saving model ...\n",
            "epoch 7:\n",
            "\tLoss decreased (0.026205 --> 0.024063).  Saving model ...\n",
            "epoch 8:\n",
            "\tLoss decreased (0.024063 --> 0.023917).  Saving model ...\n",
            "epoch 9:\n",
            "\tLoss decreased (0.023917 --> 0.021914).  Saving model ...\n",
            "epoch 10:\n",
            "\tLoss decreased (0.021914 --> 0.019333).  Saving model ...\n",
            "epoch 11:\n",
            "\tLoss decreased (0.019333 --> 0.019235).  Saving model ...\n",
            "epoch 12:\n",
            "\tLoss decreased (0.019235 --> 0.017621).  Saving model ...\n",
            "epoch 13:\n",
            "\tLoss decreased (0.017621 --> 0.016205).  Saving model ...\n",
            "epoch 14:\n",
            "\tLoss decreased (0.016205 --> 0.015456).  Saving model ...\n",
            "epoch 15:\n",
            "\tLoss decreased (0.015456 --> 0.014303).  Saving model ...\n",
            "epoch 16: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 17:\n",
            "\tLoss decreased (0.014303 --> 0.013354).  Saving model ...\n",
            "epoch 18: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 19:\n",
            "\tLoss decreased (0.013354 --> 0.013139).  Saving model ...\n",
            "epoch 20:\n",
            "\tLoss decreased (0.013139 --> 0.012629).  Saving model ...\n",
            "epoch 21:\n",
            "\tLoss decreased (0.012629 --> 0.012403).  Saving model ...\n",
            "epoch 22: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 23:\n",
            "\tLoss decreased (0.012403 --> 0.012186).  Saving model ...\n",
            "epoch 24:\n",
            "\tLoss decreased (0.012186 --> 0.011519).  Saving model ...\n",
            "epoch 25:\n",
            "\tLoss decreased (0.011519 --> 0.010684).  Saving model ...\n",
            "epoch 26: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 27: \n",
            "\tearly stopping counter: 2 out of 20\n",
            "epoch 28:\n",
            "\tLoss decreased (0.010684 --> 0.010113).  Saving model ...\n",
            "epoch 29:\n",
            "\tLoss decreased (0.010113 --> 0.009792).  Saving model ...\n",
            "epoch 30:\n",
            "\tLoss decreased (0.009792 --> 0.009208).  Saving model ...\n",
            "epoch 31: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 32:\n",
            "\tLoss decreased (0.009208 --> 0.009037).  Saving model ...\n",
            "epoch 33:\n",
            "\tLoss decreased (0.009037 --> 0.008636).  Saving model ...\n",
            "epoch 34: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 35:\n",
            "\tLoss decreased (0.008636 --> 0.008260).  Saving model ...\n",
            "epoch 36: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 37: \n",
            "\tearly stopping counter: 2 out of 20\n",
            "epoch 38:\n",
            "\tLoss decreased (0.008260 --> 0.007115).  Saving model ...\n",
            "epoch 39: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 40: \n",
            "\tearly stopping counter: 2 out of 20\n",
            "epoch 41: \n",
            "\tearly stopping counter: 3 out of 20\n",
            "epoch 42: \n",
            "\tearly stopping counter: 4 out of 20\n",
            "epoch 43: \n",
            "\tearly stopping counter: 5 out of 20\n",
            "epoch 44: \n",
            "\tearly stopping counter: 6 out of 20\n",
            "epoch 45: \n",
            "\tearly stopping counter: 7 out of 20\n",
            "epoch 46: \n",
            "\tearly stopping counter: 8 out of 20\n",
            "epoch 47: \n",
            "\tearly stopping counter: 9 out of 20\n",
            "epoch 48: \n",
            "\tearly stopping counter: 10 out of 20\n",
            "epoch 49: \n",
            "\tearly stopping counter: 11 out of 20\n",
            "epoch 50: \n",
            "\tearly stopping counter: 12 out of 20\n",
            "epoch 51: \n",
            "\tearly stopping counter: 13 out of 20\n",
            "epoch 52:\n",
            "\tLoss decreased (0.007115 --> 0.007090).  Saving model ...\n",
            "epoch 53: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 54: \n",
            "\tearly stopping counter: 2 out of 20\n",
            "epoch 55: \n",
            "\tearly stopping counter: 3 out of 20\n",
            "epoch 56:\n",
            "\tLoss decreased (0.007090 --> 0.006067).  Saving model ...\n",
            "epoch 57: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 58: \n",
            "\tearly stopping counter: 2 out of 20\n",
            "epoch 59: \n",
            "\tearly stopping counter: 3 out of 20\n",
            "epoch 60: \n",
            "\tearly stopping counter: 4 out of 20\n",
            "epoch 61: \n",
            "\tearly stopping counter: 5 out of 20\n",
            "epoch 62:\n",
            "\tLoss decreased (0.006067 --> 0.005845).  Saving model ...\n",
            "epoch 63: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 64: \n",
            "\tearly stopping counter: 2 out of 20\n",
            "epoch 65: \n",
            "\tearly stopping counter: 3 out of 20\n",
            "epoch 66: \n",
            "\tearly stopping counter: 4 out of 20\n",
            "epoch 67:\n",
            "\tLoss decreased (0.005845 --> 0.005701).  Saving model ...\n",
            "epoch 68: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 69: \n",
            "\tearly stopping counter: 2 out of 20\n",
            "epoch 70: \n",
            "\tearly stopping counter: 3 out of 20\n",
            "epoch 71: \n",
            "\tearly stopping counter: 4 out of 20\n",
            "epoch 72: \n",
            "\tearly stopping counter: 5 out of 20\n",
            "epoch 73: \n",
            "\tearly stopping counter: 6 out of 20\n",
            "epoch 74: \n",
            "\tearly stopping counter: 7 out of 20\n",
            "epoch 75:\n",
            "\tLoss decreased (0.005701 --> 0.005672).  Saving model ...\n",
            "epoch 76: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 77:\n",
            "\tLoss decreased (0.005672 --> 0.005492).  Saving model ...\n",
            "epoch 78:\n",
            "\tLoss decreased (0.005492 --> 0.005249).  Saving model ...\n",
            "epoch 79: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 80: \n",
            "\tearly stopping counter: 2 out of 20\n",
            "epoch 81: \n",
            "\tearly stopping counter: 3 out of 20\n",
            "epoch 82: \n",
            "\tearly stopping counter: 4 out of 20\n",
            "epoch 83:\n",
            "\tLoss decreased (0.005249 --> 0.004941).  Saving model ...\n",
            "epoch 84:\n",
            "\tLoss decreased (0.004941 --> 0.004886).  Saving model ...\n",
            "epoch 85: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 86: \n",
            "\tearly stopping counter: 2 out of 20\n",
            "epoch 87:\n",
            "\tLoss decreased (0.004886 --> 0.004715).  Saving model ...\n",
            "epoch 88: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 89:\n",
            "\tLoss decreased (0.004715 --> 0.004300).  Saving model ...\n",
            "epoch 90: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 91: \n",
            "\tearly stopping counter: 2 out of 20\n",
            "epoch 92: \n",
            "\tearly stopping counter: 3 out of 20\n",
            "epoch 93: \n",
            "\tearly stopping counter: 4 out of 20\n",
            "epoch 94: \n",
            "\tearly stopping counter: 5 out of 20\n",
            "epoch 95: \n",
            "\tearly stopping counter: 6 out of 20\n",
            "epoch 96: \n",
            "\tearly stopping counter: 7 out of 20\n",
            "epoch 97: \n",
            "\tearly stopping counter: 8 out of 20\n",
            "epoch 98: \n",
            "\tearly stopping counter: 9 out of 20\n",
            "epoch 99: \n",
            "\tearly stopping counter: 10 out of 20\n",
            "epoch 0:\n",
            "\tLoss decreased (inf --> 0.081100).  Saving model ...\n",
            "epoch 1:\n",
            "\tLoss decreased (0.081100 --> 0.053717).  Saving model ...\n",
            "epoch 2:\n",
            "\tLoss decreased (0.053717 --> 0.047477).  Saving model ...\n",
            "epoch 3:\n",
            "\tLoss decreased (0.047477 --> 0.041858).  Saving model ...\n",
            "epoch 4:\n",
            "\tLoss decreased (0.041858 --> 0.035852).  Saving model ...\n",
            "epoch 5:\n",
            "\tLoss decreased (0.035852 --> 0.033731).  Saving model ...\n",
            "epoch 6:\n",
            "\tLoss decreased (0.033731 --> 0.029653).  Saving model ...\n",
            "epoch 7:\n",
            "\tLoss decreased (0.029653 --> 0.027481).  Saving model ...\n",
            "epoch 8:\n",
            "\tLoss decreased (0.027481 --> 0.026085).  Saving model ...\n",
            "epoch 9:\n",
            "\tLoss decreased (0.026085 --> 0.023989).  Saving model ...\n",
            "epoch 10:\n",
            "\tLoss decreased (0.023989 --> 0.023536).  Saving model ...\n",
            "epoch 11:\n",
            "\tLoss decreased (0.023536 --> 0.021951).  Saving model ...\n",
            "epoch 12:\n",
            "\tLoss decreased (0.021951 --> 0.019290).  Saving model ...\n",
            "epoch 13:\n",
            "\tLoss decreased (0.019290 --> 0.019253).  Saving model ...\n",
            "epoch 14:\n",
            "\tLoss decreased (0.019253 --> 0.018952).  Saving model ...\n",
            "epoch 15:\n",
            "\tLoss decreased (0.018952 --> 0.016481).  Saving model ...\n",
            "epoch 16: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 17:\n",
            "\tLoss decreased (0.016481 --> 0.015773).  Saving model ...\n",
            "epoch 18:\n",
            "\tLoss decreased (0.015773 --> 0.014799).  Saving model ...\n",
            "epoch 19:\n",
            "\tLoss decreased (0.014799 --> 0.013374).  Saving model ...\n",
            "epoch 20: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 21: \n",
            "\tearly stopping counter: 2 out of 20\n",
            "epoch 22:\n",
            "\tLoss decreased (0.013374 --> 0.012316).  Saving model ...\n",
            "epoch 23: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 24: \n",
            "\tearly stopping counter: 2 out of 20\n",
            "epoch 25: \n",
            "\tearly stopping counter: 3 out of 20\n",
            "epoch 26: \n",
            "\tearly stopping counter: 4 out of 20\n",
            "epoch 27:\n",
            "\tLoss decreased (0.012316 --> 0.011449).  Saving model ...\n",
            "epoch 28: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 29:\n",
            "\tLoss decreased (0.011449 --> 0.010895).  Saving model ...\n",
            "epoch 30: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 31: \n",
            "\tearly stopping counter: 2 out of 20\n",
            "epoch 32:\n",
            "\tLoss decreased (0.010895 --> 0.010353).  Saving model ...\n",
            "epoch 33: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 34:\n",
            "\tLoss decreased (0.010353 --> 0.010288).  Saving model ...\n",
            "epoch 35: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 36: \n",
            "\tearly stopping counter: 2 out of 20\n",
            "epoch 37: \n",
            "\tearly stopping counter: 3 out of 20\n",
            "epoch 38:\n",
            "\tLoss decreased (0.010288 --> 0.009752).  Saving model ...\n",
            "epoch 39: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 40:\n",
            "\tLoss decreased (0.009752 --> 0.009515).  Saving model ...\n",
            "epoch 41: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 42:\n",
            "\tLoss decreased (0.009515 --> 0.009415).  Saving model ...\n",
            "epoch 43: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 44:\n",
            "\tLoss decreased (0.009415 --> 0.008646).  Saving model ...\n",
            "epoch 45: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 46: \n",
            "\tearly stopping counter: 2 out of 20\n",
            "epoch 47: \n",
            "\tearly stopping counter: 3 out of 20\n",
            "epoch 48:\n",
            "\tLoss decreased (0.008646 --> 0.008338).  Saving model ...\n",
            "epoch 49:\n",
            "\tLoss decreased (0.008338 --> 0.008301).  Saving model ...\n",
            "epoch 50:\n",
            "\tLoss decreased (0.008301 --> 0.007991).  Saving model ...\n",
            "epoch 51: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 52: \n",
            "\tearly stopping counter: 2 out of 20\n",
            "epoch 53: \n",
            "\tearly stopping counter: 3 out of 20\n",
            "epoch 54: \n",
            "\tearly stopping counter: 4 out of 20\n",
            "epoch 55:\n",
            "\tLoss decreased (0.007991 --> 0.007711).  Saving model ...\n",
            "epoch 56: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 57:\n",
            "\tLoss decreased (0.007711 --> 0.007686).  Saving model ...\n",
            "epoch 58:\n",
            "\tLoss decreased (0.007686 --> 0.006749).  Saving model ...\n",
            "epoch 59: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 60: \n",
            "\tearly stopping counter: 2 out of 20\n",
            "epoch 61: \n",
            "\tearly stopping counter: 3 out of 20\n",
            "epoch 62: \n",
            "\tearly stopping counter: 4 out of 20\n",
            "epoch 63: \n",
            "\tearly stopping counter: 5 out of 20\n",
            "epoch 64: \n",
            "\tearly stopping counter: 6 out of 20\n",
            "epoch 65: \n",
            "\tearly stopping counter: 7 out of 20\n",
            "epoch 66: \n",
            "\tearly stopping counter: 8 out of 20\n",
            "epoch 67: \n",
            "\tearly stopping counter: 9 out of 20\n",
            "epoch 68: \n",
            "\tearly stopping counter: 10 out of 20\n",
            "epoch 69: \n",
            "\tearly stopping counter: 11 out of 20\n",
            "epoch 70: \n",
            "\tearly stopping counter: 12 out of 20\n",
            "epoch 71:\n",
            "\tLoss decreased (0.006749 --> 0.006338).  Saving model ...\n",
            "epoch 72: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 73:\n",
            "\tLoss decreased (0.006338 --> 0.006226).  Saving model ...\n",
            "epoch 74:\n",
            "\tLoss decreased (0.006226 --> 0.005983).  Saving model ...\n",
            "epoch 75: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 76: \n",
            "\tearly stopping counter: 2 out of 20\n",
            "epoch 77:\n",
            "\tLoss decreased (0.005983 --> 0.005667).  Saving model ...\n",
            "epoch 78: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 79: \n",
            "\tearly stopping counter: 2 out of 20\n",
            "epoch 80: \n",
            "\tearly stopping counter: 3 out of 20\n",
            "epoch 81: \n",
            "\tearly stopping counter: 4 out of 20\n",
            "epoch 82: \n",
            "\tearly stopping counter: 5 out of 20\n",
            "epoch 83: \n",
            "\tearly stopping counter: 6 out of 20\n",
            "epoch 84:\n",
            "\tLoss decreased (0.005667 --> 0.005562).  Saving model ...\n",
            "epoch 85: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 86: \n",
            "\tearly stopping counter: 2 out of 20\n",
            "epoch 87: \n",
            "\tearly stopping counter: 3 out of 20\n",
            "epoch 88:\n",
            "\tLoss decreased (0.005562 --> 0.005397).  Saving model ...\n",
            "epoch 89: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 90: \n",
            "\tearly stopping counter: 2 out of 20\n",
            "epoch 91:\n",
            "\tLoss decreased (0.005397 --> 0.005320).  Saving model ...\n",
            "epoch 92: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 93:\n",
            "\tLoss decreased (0.005320 --> 0.005069).  Saving model ...\n",
            "epoch 94: \n",
            "\tearly stopping counter: 1 out of 20\n",
            "epoch 95: \n",
            "\tearly stopping counter: 2 out of 20\n",
            "epoch 96: \n",
            "\tearly stopping counter: 3 out of 20\n",
            "epoch 97: \n",
            "\tearly stopping counter: 4 out of 20\n",
            "epoch 98: \n",
            "\tearly stopping counter: 5 out of 20\n",
            "epoch 99: \n",
            "\tearly stopping counter: 6 out of 20\n",
            "CPU times: user 11min 13s, sys: 2min 11s, total: 13min 24s\n",
            "Wall time: 13min 31s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_k_low, lowest_k_low, pos_low, neg_low=searching(result_low)\n",
        "top_k_medium, lowest_k_medium, pos_medium, neg_medium=searching(result_medium)\n",
        "top_k_high, lowest_k_high, pos_high, neg_high=searching(result_high)"
      ],
      "metadata": {
        "id": "aGyy9i6VWIJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_result = pd.DataFrame(np.array([['Low', min_low, max_low, mean_price_low, num_reviews_low, mean_lenght_low, pos_low, neg_low, pos_low+neg_low], ['Medium', min_medium, max_medium, mean_price_medium, num_reviews_medium, mean_lenght_medium, pos_medium, neg_medium, pos_medium+neg_medium], ['High', min_high, max_high, mean_price_high, num_reviews_high, mean_lenght_high, pos_high, neg_high, pos_high+neg_high]]),\n",
        "                   columns=['Price', 'MinPrice', 'MaxPrice', 'MeanPrice', 'Number of reviews', 'Mean Lenght reviews', 'Number positive words', 'Number negative words', 'Total number of words'])"
      ],
      "metadata": {
        "id": "io2RdBopd7UY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "vp0fTtKaeFEd",
        "outputId": "2a98d2f8-ffc5-4b82-88dc-dda257e9380b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Price MinPrice MaxPrice           MeanPrice Number of reviews  \\\n",
              "0     Low        1       18   9.846415133418482            144845   \n",
              "1  Medium       18       60  33.978280230591324            144845   \n",
              "2    High       60     1000  192.94451310021057            144845   \n",
              "\n",
              "  Mean Lenght reviews Number positive words Number negative words  \\\n",
              "0   66.62272083951811                911227                439920   \n",
              "1   79.43576236666782                751316                652943   \n",
              "2  105.94668783872416                911637                712253   \n",
              "\n",
              "  Total number of words  \n",
              "0               1351147  \n",
              "1               1404259  \n",
              "2               1623890  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7446ecf9-9b80-4ee4-b90c-51f6a453dfdb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Price</th>\n",
              "      <th>MinPrice</th>\n",
              "      <th>MaxPrice</th>\n",
              "      <th>MeanPrice</th>\n",
              "      <th>Number of reviews</th>\n",
              "      <th>Mean Lenght reviews</th>\n",
              "      <th>Number positive words</th>\n",
              "      <th>Number negative words</th>\n",
              "      <th>Total number of words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Low</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>9.846415133418482</td>\n",
              "      <td>144845</td>\n",
              "      <td>66.62272083951811</td>\n",
              "      <td>911227</td>\n",
              "      <td>439920</td>\n",
              "      <td>1351147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Medium</td>\n",
              "      <td>18</td>\n",
              "      <td>60</td>\n",
              "      <td>33.978280230591324</td>\n",
              "      <td>144845</td>\n",
              "      <td>79.43576236666782</td>\n",
              "      <td>751316</td>\n",
              "      <td>652943</td>\n",
              "      <td>1404259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>High</td>\n",
              "      <td>60</td>\n",
              "      <td>1000</td>\n",
              "      <td>192.94451310021057</td>\n",
              "      <td>144845</td>\n",
              "      <td>105.94668783872416</td>\n",
              "      <td>911637</td>\n",
              "      <td>712253</td>\n",
              "      <td>1623890</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7446ecf9-9b80-4ee4-b90c-51f6a453dfdb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7446ecf9-9b80-4ee4-b90c-51f6a453dfdb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7446ecf9-9b80-4ee4-b90c-51f6a453dfdb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if SAVE_DATAFRAME_FILE==True:\n",
        "  df_result.to_csv('/content/Sentiment_Lexicon/Results/'+CATEGORY+'_'+negation_type+'_experiment_price.csv',index=False)"
      ],
      "metadata": {
        "id": "ed0x_hIhY832"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mean_lenght_reviews(path_category, path_metadata, cat):\n",
        "  df_low_price, df_medium_price, df_high_price = create_dataframe_price_equal_size(path_category, path_metadata)\n",
        "  _, _, _, _, mean_lenght_low = compute_statistics_dataframe(df_low_price)\n",
        "  _, _, _, _, mean_lenght_medium = compute_statistics_dataframe(df_medium_price)\n",
        "  _, _, _, _, mean_lenght_high = compute_statistics_dataframe(df_high_price)\n",
        "\n",
        "    \n",
        "  with open('/content/Sentiment_Lexicon/Results/lenght_review.txt', 'a') as f:\n",
        "      f.writelines('\\n'+cat+' Low Price'+' '+str(mean_lenght_low))\n",
        "      f.writelines('\\n'+cat+' Medium Price'+' '+str(mean_lenght_medium))\n",
        "      f.writelines('\\n'+cat+' High Price'+' '+str(mean_lenght_high))\n",
        "      f.close()"
      ],
      "metadata": {
        "id": "O8aW-4cSV0jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista_categories = ['reviews_Musical_Instruments', 'reviews_Baby', 'reviews_Cell_Phones_and_Accessories', 'reviews_Tools_and_Home_Improvement', 'reviews_Office_Products']\n",
        "\n",
        "for i, cat in enumerate(lista_categories):\n",
        "  get_mean_lenght_reviews('/content/Sentiment_Lexicon/'+cat+'.json.gz', '/content/Sentiment_Lexicon/meta_'+cat[8:]+'.json.gz', cat[8:] )"
      ],
      "metadata": {
        "id": "4aenIpKbyp-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "  \n",
        "data = {'Low': [67,62,57,56,44],\n",
        "        'Medium': [79,73,62,65,55],\n",
        "        'High': [106,102,94,85,79],\n",
        "       }\n",
        "df = pd.DataFrame(data,columns=['Low','Medium', 'High'], index = ['Musical Instruments','Baby','Cell Phones and Accessories','Tools and Home Improvement','Office Products'])\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "df.plot.barh()\n",
        "\n",
        "plt.title('Average Length of the reviews')\n",
        "plt.ylabel('Category')\n",
        "plt.xlabel('Average length of reviews')\n",
        "\n",
        "plt.savefig(\"image.eps\", bbox_inches='tight', pad_inches=0 )\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bUj4SPp2yBtq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "c1a173dd-0a1a-4e47-af19-7b5cf0ecab2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
            "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}