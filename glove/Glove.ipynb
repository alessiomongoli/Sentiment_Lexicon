{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Glove.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alessiomongoli/Sentiment_Lexicon/blob/main/glove/Glove.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import time"
      ],
      "metadata": {
        "id": "j0fDMuWq5kA6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Read glove embedding\n",
        "#Filter glove word that are present in our BoW\n",
        "#Return: Dictionary of glove word in common with our BOW (word: Embedding)\n",
        "#Return: glove word not present in the BOW (quindi non hanno polarity) (word_not_present: Embedding)\n",
        "\n",
        "def load_filter_glove_word(file, tokens, category, negation_type):\n",
        "  start = time.time()\n",
        "  #Create 2 dictionary empty\n",
        "  glove_emb={}\n",
        "  glove_wo_pol={}\n",
        "  #open file and read line for line\n",
        "  with open(file,'rb') as f:\n",
        "    glove_embeddings = pickle.load(f)  #glove embedding are a dictionary with (key,[embeddings])\n",
        "  vocab_list_glove = list()\n",
        "  #Scan glove embbedding\n",
        "  for index, key in enumerate(glove_embeddings.keys()):\n",
        "    #300 because vector with max size da molte piu informazioni\n",
        "    #faccio controllo se gli embeddings sono 300\n",
        "    if len(glove_embeddings[key]) == 300: \n",
        "      if key in tokens:\n",
        "        #if glove word are present in tokens create dictionary with(key= word that are common with our BOW, value= embeddings of the word) \n",
        "        glove_emb[key]=glove_embeddings[key]\n",
        "      else:\n",
        "        #word that are non present inn our Dictionary\n",
        "        glove_wo_pol[key]=glove_embeddings[key]\n",
        "  end = time.time()\n",
        "  with open('/content/Sentiment_Lexicon/Results/time.txt', 'a') as f:\n",
        "      f.writelines('\\n'+category+'_'+negation_type+' Glove phase: '+str(end-start)+' seconds')\n",
        "      f.close()            \n",
        "  return  glove_emb,glove_wo_pol\n",
        "\n",
        "def load__all_glove_word(file):\n",
        "  with open(file,'rb') as f:\n",
        "    glove_embeddings = pickle.load(f)\n",
        "  all_glove={}\n",
        "  for index, key in enumerate(glove_embeddings.keys()):\n",
        "    if len(glove_embeddings[key]) == 300:\n",
        "      all_glove[key]=glove_embeddings[key]\n",
        "  return all_glove\n",
        "\n",
        "def glove_test(glove_all, data):\n",
        "  glove_no_score={}\n",
        "  for index, key in enumerate(glove_all.keys()):\n",
        "    if len(glove_all[key] == 300):\n",
        "      if key not in data:\n",
        "        glove_no_score[key]=glove_all[key]\n",
        "  return glove_no_score\n"
      ],
      "metadata": {
        "id": "AUabmtpd5uHc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0oGxljnlQGge"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}